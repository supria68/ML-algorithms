{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classification using Support Vector Machines\n",
    "\n",
    "Many email services today provide spam filters that are able to classify emails into spam and non-spam email with high accuracy. Using SVM's, we can build our own spam filter. Let's train the SVM classifier to classify whether a given email, x, is spam (y = 1) or non-spam (y = 0). Each email is converted into a feature vector x ∈ R (n-dimentional).\n",
    "  \n",
    "Dataset: All data is taken from the course \"Machine Learning by Stanford University, Coursera\". This dataset(excludes email header) is based on a subset of the SpamAssassin Public Corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Email Preprocessing\n",
    "\n",
    "To use an SVM to classify emails into Spam v.s. Non-Spam, first we need to convert each email into a vector of features. The body of this email should be pre-processed i.e.,  \n",
    "a. Convert everything to lowercase  \n",
    "b. strip all HTML (< or >)  \n",
    "c. Handle the numbers  \n",
    "d. Handle URLs (http://, https://)  \n",
    "e. Handle Email Addresses  \n",
    "f. Get rid of punctuations, tabs, newlines (whitespaces)  \n",
    "g. Stem the words (“discount”, “discounts”, “discounted” and “discounting” are all replaced with “discount”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Folks,\\n \\nmy first time posting - have a bit of Unix experience, but am new to Linux.\\n\\n \\nJust got a new PC at home - Dell box with Windows XP. Added a second hard disk\\nfor Linux. Partitioned the disk and have installed Suse 7.2 from CD, which went\\nfine except it didn\\'t pick up my monitor.\\n \\nI have a Dell branded E151FPp 15\" LCD flat panel monitor and a nVidia GeForce4\\nTi4200 video card, both of which are probably too new to feature in Suse\\'s default\\nset. I downloaded a driver from the nVidia website and installed it using RPM.\\nThen I ran Sax2 (as was recommended in some postings I found on the net), but\\nit still doesn\\'t feature my video card in the available list. What next?\\n \\nAnother problem. I have a Dell branded keyboard and if I hit Caps-Lock twice,\\nthe whole machine crashes (in Linux, not Windows) - even the on/off switch is\\ninactive, leaving me to reach for the power cable instead.\\n \\nIf anyone can help me in any way with these probs., I\\'d be really grateful -\\nI\\'ve searched the \\'net but have run out of ideas.\\n \\nOr should I be going for a different version of Linux such as RedHat? Opinions\\nwelcome.\\n \\nThanks a lot,\\nPeter\\n\\n-- \\nIrish Linux Users\\' Group: ilug@linux.ie\\nhttp://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\\nList maintainer: listmaster@linux.ie\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the text file\n",
    "with open ('Data/emailSample.txt','r') as email:\n",
    "    file_contents = email.read()\n",
    "file_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary List\n",
    "\n",
    "After preprocessing the emails, there is a list of words for each email. The next step is to choose which words will be used in the classifier and which will be left out.  \n",
    "  \n",
    "For simplicity reasons, only the most frequently occuring words are considered (Vocabulary list). Since words that occur rarely in the training set are only in a few emails, they might cause the model to overfit the training set. The complete vocabulary list is in the file \"vocab.txt\". The vocabulary list was selected by choosing all words which occur at least a 100 times in the spam corpus, resulting in a list of 1899 words. In practice, a vocabulary list with about 10,000 to 50,000 words is often used.  \n",
    "  \n",
    "Given the vocabulary list, each word can be now mapped in the preprocessed emails into a list of word indices that contains the index of the word in the vocabulary list. The code in \"processEmail\" performs this mapping. In the code, a single word from the processed email is searched in the vocabulary list. If the word exists, the index of the word is added into the word_indices variable. If the word does not exist, and is therefore not in the vocabulary, the word can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's preprocess this email\n",
    "\n",
    "import re\n",
    "from string import punctuation\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "def getVocabList():\n",
    "    # a function to read the fixed vocab list.\n",
    "    with open ('Data/vocab.txt','r') as vocab:\n",
    "        vocab_dict = {}\n",
    "        for line in vocab.readlines():\n",
    "            i,word = line.split()\n",
    "            vocab_dict[word] = int(i)\n",
    "    return vocab_dict\n",
    "\n",
    "def processEmail(email_contents):\n",
    "    # Function to pre-process the email contents\n",
    "    vocabList = getVocabList() \n",
    "    word_indices = [] #init the return value\n",
    "    \n",
    "    #--------------------------- Preprocessing ----------------------------------#\n",
    "    \n",
    "    # convert to lower case\n",
    "    email_contents = email_contents.lower() \n",
    "    \n",
    "    # Strip all HTML\n",
    "    email_contents = re.sub('<[^<>]+>', ' ', email_contents)\n",
    "    \n",
    "    # Handle numbers\n",
    "    email_contents = re.sub('[0-9]+', 'number', email_contents)\n",
    "    \n",
    "    # Handle URLs\n",
    "    email_contents = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', email_contents)\n",
    "    \n",
    "    # Handle $ sign (most spam emails are lottery/discount emails!)\n",
    "    email_contents = re.sub('[$]+', 'dollar', email_contents)\n",
    "    \n",
    "    print('\\n---------- Processed Email ---------------\\n')\n",
    "    \n",
    "    # Get rid of any punctuation.\n",
    "    email_contents = email_contents.translate(str.maketrans('', '', punctuation))\n",
    "\n",
    "    # Split the email text string into individual words.\n",
    "    word_content = email_contents.split()\n",
    "    \n",
    "    l = 0\n",
    "    \n",
    "    for token in word_content:\n",
    "\n",
    "        # Remove any non alphanumeric characters.\n",
    "        token = re.sub('[^a-zA-Z0-9]', '', token)\n",
    "        \n",
    "        # Create the stemmer.\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        \n",
    "        # Stem the word.\n",
    "        token = stemmer.stem(token.strip())\n",
    "\n",
    "        # Skip the word if it is too short\n",
    "        if len(token) < 1:\n",
    "           continue\n",
    "        \n",
    "        # Look up the word in the dictionary and add to word_indices if found.\n",
    "        if token in vocabList:\n",
    "            idx = vocabList[token]\n",
    "            word_indices.append(idx)\n",
    "\n",
    "        # Print to screen, ensuring that the output lines are not too long.\n",
    "        if l + len(token) + 1 > 78:\n",
    "            print()\n",
    "            l = 0\n",
    "        print(token, end=' ')\n",
    "        l = l + len(token) + 1\n",
    "\n",
    "    return word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- Processed Email ---------------\n",
      "\n",
      "folk my first time post have a bit of unix experi but am new to linux just \n",
      "got a new pc at home dell box with window xp ad a second hard disk for linux \n",
      "partit the disk and have instal suse numbernumb from cd which went fine \n",
      "except it didnt pick up my monitor i have a dell brand enumberfpp number lcd \n",
      "flat panel monitor and a nvidia geforcenumb tinumb video card both of which \n",
      "are probabl too new to featur in suse default set i download a driver from \n",
      "the nvidia websit and instal it use rpm then i ran saxnumb as was recommend \n",
      "in some post i found on the net but it still doesnt featur my video card in \n",
      "the avail list what next anoth problem i have a dell brand keyboard and if i \n",
      "hit capslock twice the whole machin crash in linux not window even the onoff \n",
      "switch is inact leav me to reach for the power cabl instead if anyon can help \n",
      "me in ani way with these prob id be realli grate ive search the net but have \n",
      "run out of idea or should i be go for a differ version of linux such as \n",
      "redhat opinion welcom thank a lot peter irish linux user group emailaddr \n",
      "httpwwwlinuxiemailmanlistinfoilug for unsubscript inform list maintain \n",
      "emailaddr \n",
      "\n",
      "\n",
      " -------------Word Indices--------------------------\n",
      "\n",
      "[662, 1084, 652, 1694, 1280, 756, 186, 1162, 1752, 594, 225, 64, 1099, 1699, 960, 902, 726, 1099, 1228, 124, 787, 427, 208, 1860, 1855, 1885, 21, 1464, 752, 464, 666, 960, 1217, 1666, 464, 74, 756, 847, 1627, 688, 259, 1840, 1832, 647, 583, 883, 1249, 1760, 1084, 1061, 756, 427, 210, 1120, 1208, 1061, 74, 1792, 246, 204, 1162, 1840, 1308, 1708, 1099, 1699, 626, 825, 1627, 417, 1494, 487, 492, 688, 1666, 1824, 74, 847, 883, 1437, 1671, 116, 1376, 825, 1545, 1280, 677, 1171, 1666, 1095, 225, 883, 1590, 626, 1084, 1792, 246, 825, 1666, 139, 961, 1835, 1101, 80, 1309, 756, 427, 210, 909, 74, 810, 785, 1666, 1845, 988, 380, 825, 960, 1113, 1855, 571, 1666, 1630, 877, 940, 1018, 1699, 1365, 666, 1666, 1284, 230, 850, 810, 86, 238, 771, 1018, 825, 75, 1860, 1675, 804, 162, 1371, 1462, 1666, 1095, 225, 756, 1440, 1192, 1162, 805, 1182, 1510, 162, 718, 666, 452, 1790, 1162, 960, 1613, 116, 1379, 1177, 1830, 1664, 980, 876, 960, 1773, 735, 531, 666, 840, 961, 995, 531]\n"
     ]
    }
   ],
   "source": [
    "# Extract features.\n",
    "word_indices = processEmail(file_contents)\n",
    "\n",
    "# Print stats.\n",
    "print('\\n\\n\\n -------------Word Indices--------------------------\\n')\n",
    "print(word_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Features from Emails\n",
    "\n",
    "The feature extraction converts each email into a vector in R (n-dimensional). For this, n=# words in vocabulary list should be used. Specifically, xi=1 if the i-th word is in the email and xi=0 if the i-th word is not present in the email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from sample email...\n",
      "\n",
      "Length of feature vector: 1899\n",
      "\n",
      "Number of non-zero entries: 120\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def emailFeatures(word_indices):\n",
    "    # This function takes in a word_indices vector and produces a feature vector from the word indices.\n",
    "    \n",
    "    n = 1899 # total number of words in the vocab.txt file\n",
    "    x = np.zeros((n, 1)) #initial feature vector\n",
    "    \n",
    "    for i in range(len(word_indices)):\n",
    "        x[word_indices[i]] = 1\n",
    "    \n",
    "    return x\n",
    "\n",
    "features = emailFeatures(word_indices)\n",
    "\n",
    "print('Extracting features from sample email...\\n')\n",
    "print('Length of feature vector: {}\\n'.format(len(features)))\n",
    "print('Number of non-zero entries: {}'.format(np.sum(features > 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SVM for Spam Classification\n",
    "\n",
    "Load the preprocessed training dataset to train the SVM classifier. spamTrain.mat contains 4000 training examples of spam and non-spam email, while spamTest.mat contains 1000 test examples. Each original email was processed using the \"processEmail\" and \"emailFeatures\" functions and converted into a vector x (i) ∈ R^1899 .  \n",
    "After loading the dataset, proceed to train a SVM to classify between spam (y = 1) and non-spam (y = 0) emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 1899), (4000, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = sio.loadmat('Data/spamTrain.mat')\n",
    "X = train_data.get('X')\n",
    "y = train_data.get('y')\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVC classifier...\n",
      "\n",
      "\n",
      "Model trained succesfully! Test it out to get the accuracy!\n"
     ]
    }
   ],
   "source": [
    "print('Training SVC classifier...\\n\\n')\n",
    "\n",
    "C = 0.1\n",
    "model = SVC(C, 'linear')\n",
    "model.fit(X, y.ravel())\n",
    "print('Model trained succesfully! Test it out to get the accuracy!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Spam Classification\n",
    "\n",
    "After training the classifier, we can evaluate it on a test set. Test set is loaded from spamTest.mat. Evaluate SVM classifier on the test features(Xtest) Vs target (ytest). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 1899), (1000, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classifier for test data \n",
    "test_data = sio.loadmat('Data/spamTest.mat')\n",
    "X_test = test_data.get('Xtest')\n",
    "y_test = test_data.get('ytest')\n",
    "\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the trained Linear SVM on a test set ...\n",
      "Test Accuracy: 98.90%\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating the trained Linear SVM on a test set ...')\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print('Test Accuracy: {0:.2f}%'.format(np.mean((prediction == y_test.ravel()).astype(int)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Predictors for Spam\n",
    "\n",
    "To better understand how the spam classifier works, we can inspect the parameters to see which words the classifier thinks are the most predictive of spam. Display the top 10 words that has the largest positive values in the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top predictors of spam: \n",
      "\n",
      "pleas      (0.261169)\n",
      "price      (0.267298)\n",
      "will       (0.269724)\n",
      "dollar     (0.323632)\n",
      "basenumb   (0.345064)\n",
      "visit      (0.367710)\n",
      "guarante   (0.383622)\n",
      "remov      (0.422869)\n",
      "click      (0.465916)\n",
      "our        (0.500614)\n"
     ]
    }
   ],
   "source": [
    "# Get the weights.\n",
    "weights = model.coef_[0]\n",
    "\n",
    "# Get the 10 indices that sort the most important weights.\n",
    "indices = weights.argsort()[-10:]\n",
    "\n",
    "# Return a sorted list from the dictionary.\n",
    "vocabList = sorted(getVocabList())\n",
    "\n",
    "print('Top predictors of spam: \\n');\n",
    "for i in indices: \n",
    "    print( '{0:10s} ({1:8f})'.format(vocabList[i], float(weights[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, If the email contains words such as guarante or dollar, it is likely to be classified as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
